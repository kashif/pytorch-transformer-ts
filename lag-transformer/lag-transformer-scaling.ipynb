{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â import wandb\n",
    "\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from estimator import LagTransformerEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDatasetIterator:\n",
    "    def __init__(self, datasets, seed, weights):\n",
    "        self._datasets = [iter(el) for el in datasets]\n",
    "        self._weights = weights\n",
    "        self._rng = random.Random(seed)\n",
    "\n",
    "    def __next__(self):\n",
    "        (dataset,) = self._rng.choices(self._datasets, weights=self._weights, k=1)\n",
    "        return next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDataset:\n",
    "    def __init__(self, datasets, seed=None, weights=None):\n",
    "        self._seed = seed\n",
    "        self._datasets = datasets\n",
    "        self._weights = weights\n",
    "        n_datasets = len(datasets)\n",
    "        if weights is None:\n",
    "            self._weights = [1 / n_datasets] * n_datasets\n",
    "\n",
    "    def __iter__(self):\n",
    "        return CombinedDatasetIterator(self._datasets, self._seed, self._weights)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(ds) for ds in self._datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gluonts_ds = [\n",
    "        get_dataset(\"airpassengers\").train,\n",
    "        # get_dataset(\"australian_electricity_demand\").train,\n",
    "        # get_dataset(\"car_parts_without_missing\").train,\n",
    "        # get_dataset(\"cif_2016\").train,\n",
    "        # get_dataset(\"covid_deaths\").train,\n",
    "        # get_dataset(\"electricity\").train,\n",
    "        # get_dataset(\"electricity_weekly\").train,\n",
    "        # get_dataset(\"exchange_rate\").train,\n",
    "        # get_dataset(\"fred_md\").train,\n",
    "        # get_dataset(\"hospital\").train,\n",
    "        # get_dataset(\"kaggle_web_traffic_weekly\").train,\n",
    "        # get_dataset(\"kdd_cup_2018_without_missing\").train,\n",
    "        # get_dataset(\"london_smart_meters_without_missing\").train,\n",
    "        # get_dataset(\"nn5_daily_with_missing\").train,\n",
    "        # get_dataset(\"nn5_weekly\").train,\n",
    "        # get_dataset(\"pedestrian_counts\").train,\n",
    "        # get_dataset(\"rideshare_without_missing\").train,\n",
    "        # get_dataset(\"saugeenday\").train,\n",
    "        # get_dataset(\"solar-energy\").train,\n",
    "        # get_dataset(\"solar_10_minutes\").train,\n",
    "        # get_dataset(\"solar_weekly\").train,\n",
    "        # get_dataset(\"taxi_30min\").train,\n",
    "        # get_dataset(\"temperature_rain_without_missing\").train,\n",
    "        # get_dataset(\"tourism_monthly\").train,\n",
    "        # get_dataset(\"uber_tlc_daily\").train,\n",
    "        # get_dataset(\"uber_tlc_hourly\").train,\n",
    "        # get_dataset(\"vehicle_trips_without_missing\").train,\n",
    "        # get_dataset(\"weather\").train,\n",
    "        # get_dataset(\"wiki-rolling_nips\").train,\n",
    "        # get_dataset(\"m4_daily\").train,\n",
    "        # get_dataset(\"m4_hourly\").train,\n",
    "        # get_dataset(\"m4_monthly\").train,\n",
    "        # get_dataset(\"m4_quarterly\").train,\n",
    "        # get_dataset(\"m4_yearly\").train,\n",
    "        # get_dataset(\"wind_farms_without_missing\").train,\n",
    "]\n",
    "dataset = CombinedDataset(gluonts_ds, weights=[sum([len(x[\"target\"]) for x in d]) for d in gluonts_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_dataset(\"m4_weekly\").test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = get_dataset(\"m4_weekly\").metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "estimator = LagTransformerEstimator(\n",
    "    prediction_length=512,\n",
    "    context_length=512, # block_size: int = 2048 \n",
    "    batch_size=16, # 4\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    nhead=4,\n",
    "    d_model=128, # 4096\n",
    "    dim_feedforward=128*2,\n",
    "    scaling=\"std\",\n",
    "    \n",
    "    aug_prob=1.0,\n",
    "    aug_rate=0.2,\n",
    "    \n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs=dict(max_epochs=300, accelerator=\"gpu\", precision=\"bf16-mixed\", logger=WandbLogger()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator = LagTransformerEstimator(\n",
    "    prediction_length=512,\n",
    "    context_length=512, # block_size: int = 2048 \n",
    "    batch_size=16, # 4\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    nhead=4,\n",
    "    d_model=128, # 4096\n",
    "    dim_feedforward=128*2,\n",
    "    scaling=\"std\",\n",
    "    \n",
    "    aug_prob=1.0,\n",
    "    aug_rate=0.2,\n",
    "    \n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs=dict(max_epochs=300, accelerator=\"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_output = estimator.train_model(\n",
    "    training_data=dataset, \n",
    "    validation_data=val_dataset,\n",
    "    shuffle_buffer_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(\"traffic\").test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_dataset, predictor=predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_workers is limited to 10 if cpu has more cores\n",
    "num_workers = min(multiprocessing.cpu_count(), 10)\n",
    "\n",
    "evaluator = Evaluator(num_workers=num_workers)\n",
    "\n",
    "agg_metrics, ts_metrics = evaluator(\n",
    "    iter(tss), iter(forecasts), num_series=len(test_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_metrics.plot(x=\"MSIS\", y=\"MAPE\", kind=\"scatter\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts, tss)), 9):\n",
    "    ax = plt.subplot(3, 3, idx+1)\n",
    "    forecast.plot(color='g', show_label=True)\n",
    "    ts[-3 * 24:][0].plot(label=\"target\")\n",
    "    plt.xticks(rotation=60)\n",
    "    ax.set_title(forecast.item_id)\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
